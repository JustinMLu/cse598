{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0052d469",
   "metadata": {},
   "source": [
    "# EECS 598 Lab 2: Exploring Environments and Action Spaces in Mujoco Playground\n",
    "\n",
    "![lab2_poster](lab2_poster.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe0d94",
   "metadata": {},
   "source": [
    "This notebook is worth **80 points**. Questions and implementation are marked with relevent `#TODO(student)` markers.\n",
    "\n",
    "**Due:** Friday, Sep 5 @ 1pm\n",
    "\n",
    "\n",
    "Before starting the assignment, please put your name and UMID in the following format:\n",
    "\n",
    "Firstname LASTNAME, #00000000 (ex. Drew SCHEFFER #31415926)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e2a8b0",
   "metadata": {},
   "source": [
    "**YOUR ANSWER BELOW**\n",
    "\n",
    "Justin LU, #85477350"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051985ae",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4d4e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, types, importlib\n",
    "\n",
    "# Create a tiny fake 'imp' module exposing only 'reload'\n",
    "_imp = types.ModuleType(\"imp\")\n",
    "_imp.reload = importlib.reload\n",
    "sys.modules[\"imp\"] = _imp\n",
    "\n",
    "# load autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Setting environment variable to use GPU rendering:')\n",
    "%env MUJOCO_GL=egl\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import packages for plotting and creating graphics\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "from typing import Callable, NamedTuple, Optional, Union, List\n",
    "\n",
    "# Graphics and plotting.\n",
    "print('Installing mediapy:')\n",
    "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
    "!pip install -q mediapy\n",
    "import mediapy as media\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# More legible printing from numpy.\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8f44b",
   "metadata": {},
   "source": [
    "### Google Colab Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71ce41",
   "metadata": {},
   "source": [
    "Next, we'll run a few fommands to set up the environment on Google Colab. If you are running this notebook locally you can skip this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e6299",
   "metadata": {},
   "source": [
    "Run the following to mount this notebook to your Google Drive. Follow the link and sign into the Google account following the prompts. Use the same Google account that you used to store this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f0b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4786706d",
   "metadata": {},
   "source": [
    "Now update the path below to point to the folder in your Google Drive where you uploaded this notebook. If everything worked correctly you should see the following filenames: [`custom_env.py`, `02_lab.ipynb`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2f3840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded project 2\n",
    "# Example: If you create a 2025FA folder and put all the files under Lab2, then '2025FA/Lab2'\n",
    "# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '2025FA/Lab2'\n",
    "\n",
    "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = None\n",
    "GOOGLE_DRIVE_PATH_LAB2 = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
    "\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH_LAB2))\n",
    "\n",
    "# Add to path and change directory for good measure\n",
    "sys.path.append(GOOGLE_DRIVE_PATH_LAB2)\n",
    "os.chdir(GOOGLE_DRIVE_PATH_LAB2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dfee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "import distutils.util\n",
    "import os\n",
    "import subprocess\n",
    "if subprocess.run('nvidia-smi').returncode:\n",
    "  raise RuntimeError(\n",
    "      'Cannot communicate with GPU. '\n",
    "      'Make sure you are using a GPU Colab runtime. '\n",
    "      'Go to the Runtime menu and select Choose runtime type.')\n",
    "\n",
    "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
    "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
    "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
    "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
    "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
    "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
    "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
    "    f.write(\"\"\"{\n",
    "    \"file_format_version\" : \"1.0.0\",\n",
    "    \"ICD\" : {\n",
    "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
    "    }\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc4b0ba",
   "metadata": {},
   "source": [
    "## Mujoco Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mujoco\n",
    "!pip install mujoco_mjx\n",
    "!pip install brax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd585ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  print('Checking that the installation succeeded:')\n",
    "  import mujoco\n",
    "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
    "except Exception as e:\n",
    "  raise e from RuntimeError(\n",
    "      'Something went wrong during installation. Check the shell output above '\n",
    "      'for more information.\\n'\n",
    "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
    "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
    "\n",
    "print('Installation successful.')\n",
    "\n",
    "# Tell XLA to use Triton GEMM, this improves steps/sec by ~30% on some GPUs\n",
    "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
    "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
    "os.environ['XLA_FLAGS'] = xla_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import MuJoCo, MJX, and Brax\n",
    "from datetime import datetime\n",
    "from etils import epath\n",
    "import functools\n",
    "from IPython.display import HTML\n",
    "from typing import Any, Dict, Sequence, Tuple, Union\n",
    "import os\n",
    "from ml_collections import config_dict\n",
    "\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "import numpy as np\n",
    "from flax.training import orbax_utils\n",
    "from flax import struct\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapy as media\n",
    "from orbax import checkpoint as ocp\n",
    "\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "\n",
    "from brax import base\n",
    "from brax import envs\n",
    "from brax import math\n",
    "from brax.base import Base, Motion, Transform\n",
    "from brax.base import State as PipelineState\n",
    "from brax.envs.base import Env, PipelineEnv, State\n",
    "from brax.mjx.base import State as MjxState\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "from brax.io import html, mjcf, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d738d6e3",
   "metadata": {},
   "source": [
    "## Introduction to Mujoco & MJX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b82809",
   "metadata": {},
   "source": [
    "MJX is an implementation of MuJoCo written in [JAX](https://jax.readthedocs.io/en/latest/index.html). The appeal of MJX is that it enables large batch simulation on GPU/TPU, which is especially suitable for reinforcement learning workloads. For today, however, we'll mainly look past the fast rendering of MJX and focus on creating basic simulation environments and agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68042536",
   "metadata": {},
   "source": [
    "The best way to learn about MJX/Mujoco is to get our hands dirty! Let's create a simple mujoco world using their XML system to get a sense of what is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb2dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = \"\"\"\n",
    "<mujoco>\n",
    "  <worldbody>\n",
    "    <light name=\"top\" pos=\"0 0 1\"/>\n",
    "    <body name=\"box_and_sphere\" euler=\"0 0 -30\">\n",
    "      <joint name=\"swing\" type=\"hinge\" axis=\"1 -1 0\" pos=\"-.2 -.2 -.2\"/>\n",
    "      <geom name=\"red_box\" type=\"box\" size=\".2 .2 .2\" rgba=\"1 0 0 1\"/>\n",
    "      <geom name=\"green_sphere\" pos=\".2 .2 .2\" size=\".1\" rgba=\"0 1 0 1\"/>\n",
    "    </body>\n",
    "  </worldbody>\n",
    "</mujoco>\n",
    "\"\"\"\n",
    "\n",
    "# Load the model, get the data, then render\n",
    "mj_model = mujoco.MjModel.from_xml_string(xml)\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "renderer = mujoco.Renderer(mj_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565680e",
   "metadata": {},
   "source": [
    "A few very important structures have already showed up: \n",
    "1. `mj_model`: A compiled model of the XML. This contains quantities that DO NOT change over time. For a list of everything that can be stored in this variable see [`mjmodel.h`](https://github.com/google-deepmind/mujoco/blob/main/include/mujoco/mjmodel.h)\n",
    "2. `mj_data`: simulation state (i.e. positions, velocities, forces, etc)\n",
    "3. `renderer`: a CPU renderer for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21928b46",
   "metadata": {},
   "source": [
    "#### `mjModel`\n",
    "\n",
    "A compiled model of the XML. This contains quantities that DO NOT change over time. For a list of everything that can be stored in this variable see [`mjmodel.h`](https://github.com/google-deepmind/mujoco/blob/main/include/mujoco/mjmodel.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03125167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mj_model examples\n",
    "print(\"num geoms:\", mj_model.ngeom)\n",
    "print(\"geom colors:\", mj_model.geom_rgba)\n",
    "\n",
    "mj_model.geom(\"green_sphere\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866b1f37",
   "metadata": {},
   "source": [
    "Each element in the scene is given a unique ID that can be used to access its quantities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c73edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_name = \"green_sphere\"\n",
    "\n",
    "# TODO(student): given the name of a geom, access its color\n",
    "#       use the function mujoco.mj_name2id and the mj_model.geom_rgba property\n",
    "answer = None\n",
    "print(\"Answer = \", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60468b20",
   "metadata": {},
   "source": [
    "#### `mjData` \n",
    "\n",
    "contains the *state* of the environment and the quantities that depend on it. The state is made up of time, *generalized* positions, and *generalized* velocities in a configuration space. You can access these quantities via `data.time`, `data.qpos`, and` data.qvel` respectively. `mjData` also contains *functions of the state*, for example cartesian positions of the objects in the world frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddf4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mujoco.MjData(mj_model)\n",
    "print(data.geom_xpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f9564",
   "metadata": {},
   "source": [
    "This output above might look counterintuitive. If you recall, in the XML we explicitly set the cartesian positions in the world frame, right? Well, it turns out that derived quantities in `mjData` need to be explicitly propagated. In this simple case the minimal required function is `mj_kinematics` which compultes global Cartesian poses for all objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_kinematics(mj_model, data)\n",
    "print('raw access:\\n', data.geom_xpos)\n",
    "\n",
    "# MjData also supports named access:\n",
    "print('\\nnamed access:\\n', data.geom('green_sphere').xpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023c21a",
   "metadata": {},
   "source": [
    "#### Rendering a Simple Environment Rollout on the CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad82109",
   "metadata": {},
   "source": [
    "First, let's see how to render a rollout using the CPU simulation. Feel free to poke around and explore the different variables. \n",
    "\n",
    "Pay attention to the use of the functions `mujoco.mj_resetData` and `mujoco.mj_step` and connect them to what we learned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7873a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable joint visualization option:\n",
    "scene_option = mujoco.MjvOption()\n",
    "scene_option.flags[mujoco.mjtVisFlag.mjVIS_JOINT] = True\n",
    "\n",
    "duration = 5  # (s)\n",
    "framerate = 60  # (Hz)\n",
    "\n",
    "frames = []\n",
    "mujoco.mj_resetData(mj_model, mj_data)\n",
    "while mj_data.time < duration:\n",
    "  mujoco.mj_step(mj_model, mj_data)\n",
    "  if len(frames) < mj_data.time * framerate:\n",
    "    renderer.update_scene(mj_data, scene_option=scene_option)\n",
    "    pixels = renderer.render()\n",
    "    frames.append(pixels)\n",
    "\n",
    "# Simulate and display video.\n",
    "media.show_video(frames, fps=framerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257bfe68",
   "metadata": {},
   "source": [
    "#### Rendering the Same Simple Environment Rollout on the GPU\n",
    "Now let's try doing the same thing on the GPU using Jax! First, we put the model and the data on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb496430",
   "metadata": {},
   "outputs": [],
   "source": [
    "mjx_model = mjx.put_model(mj_model)\n",
    "mjx_data = mjx.put_data(mj_model, mj_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b18990",
   "metadata": {},
   "source": [
    "See how the data types change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1fa807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mj_data.qpos, type(mj_data.qpos))\n",
    "print(mjx_data.qpos, type(mjx_data.qpos), mjx_data.qpos.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cb16b3",
   "metadata": {},
   "source": [
    "In the example below, we use `mjx.step` instead of `mujoco.mj_step`, and we also [`jax.jit`](https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html) the `mjx.step` so that it runs efficiently on the GPU. For each frame, we convert the `mjx.Data` back to `mjData` so that we can use the MuJoCo renderer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb94fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_step = jax.jit(mjx.step)\n",
    "\n",
    "frames = []\n",
    "mujoco.mj_resetData(mj_model, mj_data)\n",
    "mjx_data = mjx.put_data(mj_model, mj_data)\n",
    "while mjx_data.time < duration:\n",
    "  mjx_data = jit_step(mjx_model, mjx_data)\n",
    "  if len(frames) < mjx_data.time * framerate:\n",
    "    mj_data = mjx.get_data(mj_model, mjx_data)\n",
    "    renderer.update_scene(mj_data, scene_option=scene_option)\n",
    "    pixels = renderer.render()\n",
    "    frames.append(pixels)\n",
    "\n",
    "media.show_video(frames, fps=framerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22100fd",
   "metadata": {},
   "source": [
    "Interestingly, rendering this simple simulation on the GPU is not very efficient as you might have noticed. The GPU simulation likely took >10x the amount of time! Running single-threaded physics simulation is not efficient compared to a high performance CPU. The advantage of MJX in general is that we can run **many, many** environments in parallel on a GPU/TPU. \n",
    "\n",
    "[Read this if you want to learn more](https://mujoco.readthedocs.io/en/stable/mjx.html#mjx-the-sharp-bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ba529",
   "metadata": {},
   "source": [
    "as a test, let's render 1000 steps of the physics simulation for 4096 parallel envs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba948ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "NUM_ENVS = 4096\n",
    "\n",
    "start_time = time.time()\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng = jax.random.split(rng, NUM_ENVS)\n",
    "batch = jax.vmap(lambda rng: mjx_data.replace(qpos=jax.random.uniform(rng, (1,))))(rng)\n",
    "jit_step = jax.jit(jax.vmap(mjx.step, in_axes=(None, 0)))\n",
    "\n",
    "num_steps = 1000\n",
    "for i in range(num_steps):\n",
    "    batch = jit_step(mjx_model, batch)\n",
    "\n",
    "print(\"The frames per second is \", NUM_ENVS*num_steps / (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad3b42",
   "metadata": {},
   "source": [
    "`TODO(student)` **TASK 1**: describe in your own words how jax random numbers work. What is the purpose of `jax.random.split`? (5 pts)\n",
    "\n",
    "**Answer:**  [fill this in]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad420e6",
   "metadata": {},
   "source": [
    "## Loading an Environment and Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c0fb53",
   "metadata": {},
   "source": [
    "The loading and initialization of the simulation world and its agents are largely handled in our *environment file*. In our case, the environment file is [`custom_env.py`](./custom_env.py). Check out this file for a few minutes, looking at the main functions that it impliments. Especially `render()`, `step()`, `get_obs()`, and `reset()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c78195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_env import UnitreeGo2Env\n",
    "from custom_env import UNITREEGO2_ROOT_PATH\n",
    "\n",
    "envs.register_environment('unitreego2', UnitreeGo2Env)\n",
    "\n",
    "print(\"List the assets used to create the simulation environment\")\n",
    "os.listdir(UNITREEGO2_ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e3611",
   "metadata": {},
   "source": [
    "Load the environment and agent, then render the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the environment\n",
    "env_name = 'unitreego2'\n",
    "env = envs.get_environment(env_name)\n",
    "\n",
    "# jit reset/step functions for fast runtime\n",
    "jit_reset = jax.jit(env.reset)\n",
    "jit_step = jax.jit(env.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = jit_reset(jax.random.PRNGKey(0))\n",
    "\n",
    "plt.imshow(env.render([state.pipeline_state], camera='track')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbaf23e",
   "metadata": {},
   "source": [
    "`TODO(student)` **TASK 2**: Similarly, we can rollout an entire trajectory in our environment using the `jit_step()` function. **(10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c021bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = jit_reset(jax.random.PRNGKey(0))\n",
    "\n",
    "rollout = [state.pipeline_state]\n",
    "\n",
    "# grab a trajectory\n",
    "for i in range(500):\n",
    "    \n",
    "    # TODO(student): Sample the ZERO action for the robot. For now, just create a `jax.array` \n",
    "    # with the same size as the number of actuators. Set each element of the array to be 0. \n",
    "    # hint 1: you can use the `env.sys.nu` property to get the number of actuators/motors\n",
    "    # hint 2: the `jp` module is an alias for jax.numpy which has similar functionality to \n",
    "    # numpy (i.e. jp.zeros, jp.ones, jp.array, etc)\n",
    "    action = None\n",
    "    \n",
    "    # TODO(student): Take a \"jit_step\" in the environment. See the custom_env.py file for details \n",
    "    # on the arguments the function takes and what it returns. \n",
    "    state = None\n",
    "    \n",
    "    rollout.append(state.pipeline_state)\n",
    "\n",
    "media.show_video(env.render(rollout, camera=\"track\"), fps=1.0 / env.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7885b81e",
   "metadata": {},
   "source": [
    "### Randomize the Starting Pose of the Robot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5dd440",
   "metadata": {},
   "source": [
    "That's pretty cool! Our agent has successfully been loaded into the environment! One reasonable next step is to control where the agent is spawned into the environment. \n",
    "\n",
    "`TODO(student)` **TASK 3**: Navigate to the `custom_env.py` file and fill out the `TODO(student)` related to spawning the agent in different positions. **(10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4494d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_env import UnitreeGo2Env\n",
    "\n",
    "env_rand = envs.get_environment(\"unitreego2\", randomize_initial_pos=True)\n",
    "\n",
    "# jit reset/step functions for fast runtime\n",
    "jit_reset = jax.jit(env_rand.reset)\n",
    "jit_step = jax.jit(env_rand.step)\n",
    "state = jit_reset(jax.random.PRNGKey(2))\n",
    "\n",
    "rollout = [state.pipeline_state]\n",
    "\n",
    "# grab a trajectory\n",
    "for i in range(500):\n",
    "    action = jp.zeros(env_rand.sys.nu)\n",
    "    state = jit_step(state, action)\n",
    "    rollout.append(state.pipeline_state)\n",
    "\n",
    "media.show_video(env_rand.render(rollout, camera=\"track\"), fps=1.0 / env_rand.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69560ccf",
   "metadata": {},
   "source": [
    "## Exploring the state and action space\n",
    "\n",
    "In this section, we'll begin to explore how to use and modify the agent's *state* and *action* spaces. First, I encourage you to simply play with the robot model. What does the `action` variable seem to represet? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43caae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = envs.get_environment(\"unitreego2\")\n",
    "\n",
    "# jit reset/step functions for fast runtime\n",
    "jit_reset = jax.jit(env.reset)\n",
    "jit_step = jax.jit(env.step)\n",
    "\n",
    "\n",
    "state = jit_reset(jax.random.PRNGKey(0))\n",
    "\n",
    "state = jit_reset(jax.random.PRNGKey(0))\n",
    "\n",
    "rollout = [state.pipeline_state]\n",
    "\n",
    "# grab a trajectory\n",
    "for i in range(500):\n",
    "    # TODO(student): Modify and change the action below, think about what happens. What happens? \n",
    "    # What does the zero action do? How is it defined? \n",
    "    action = jp.zeros(env.sys.nu)\n",
    "    \n",
    "    # Take a step in the environment\n",
    "    state = jit_step(state, action)\n",
    "    \n",
    "    \n",
    "    rollout.append(state.pipeline_state)\n",
    "\n",
    "media.show_video(env.render(rollout, camera=\"track\"), fps=1.0 / env.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb8be67",
   "metadata": {},
   "source": [
    "`TODO(student)` **TASK 4**: How is the \"action\" defined in this environment? What do the values in the `action` variable represent? **(5 pts)**\n",
    "\n",
    "**Answer:** [Answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d380f",
   "metadata": {},
   "source": [
    "After exploring, fill out the following with your answers: **(5 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330fece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fill out the following\n",
    "initial_joint_values = None\n",
    "min_joint_values = None\n",
    "max_joint_values = None\n",
    "\n",
    "print(\"Answers:\", initial_joint_values, min_joint_values, max_joint_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e214b25",
   "metadata": {},
   "source": [
    "We get access to the robot \"state\" after each environment step. The `pipeline_state` is stored in the `rollout` array. \n",
    "\n",
    "`#TODO(student)` **TASK 5**: Play around with the data and plot the right foot position over time using matplotlib (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b79fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(student): Use the \"rollout\" variable to plot the position of the front \n",
    "# right foot over time while performing some non-zero action\n",
    "\n",
    "import mujoco\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#TODO(student). Use the function mujoco.mj_name2id to get the geom id of the front right foot. \n",
    "# You can find an in the custom_env.py file, however, the \"type\" parameter will no longer be a body, but a geom. \n",
    "fr_foot_geom_id = None\n",
    "\n",
    "foot_poses = []\n",
    "\n",
    "for state in rollout:\n",
    "    # TODO(student): access the position of the front right foot using the fr_foot_geom_id you calculated. \n",
    "    # hint: remember the xyz position of geoms are stored in the geom_xpos property of the MjData object.\n",
    "    foot_pos = None\n",
    "    foot_poses.append(np.array(foot_pos))\n",
    "    \n",
    "    \n",
    "\n",
    "foot_poses = np.stack(foot_poses)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c773b36c",
   "metadata": {},
   "source": [
    "## Modifying the Environment Class (and kicking your robot)\n",
    "\n",
    "In this section, we'll get more experience changing the environment directly! Up until now, the robot lives in its lonely world undisturbed. Let's change that! \n",
    "\n",
    "In many simulated environments, researchers will inflict periodic, random \"pushes\" in an effort to make their robots more robust to external disturbances. You'll code up a simple version of this behavior in our environment! \n",
    "\n",
    "`TODO(student)` **TASK 6**: Head over to [`custom_env.py`](./custom_env.py) and impliment the \"kick\" TODOs at the top of the `step()` function. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aabf3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_env import UnitreeGo2Env\n",
    "\n",
    "env = envs.get_environment(\"unitreego2\", kick_vel=0.5)\n",
    "\n",
    "# jit reset/step functions for fast runtime\n",
    "jit_reset = jax.jit(env.reset)\n",
    "jit_step = jax.jit(env.step)\n",
    "state = jit_reset(jax.random.PRNGKey(0))\n",
    "\n",
    "state = jit_reset(jax.random.PRNGKey(0))\n",
    "\n",
    "rollout = [state.pipeline_state]\n",
    "all_obs = [state.obs]\n",
    "all_infos = [state.info]\n",
    "\n",
    "# grab a trajectory\n",
    "for i in range(500):\n",
    "    action = jp.zeros(env.sys.nu) # Don't modify\n",
    "    \n",
    "    # Take a step in the environment\n",
    "    state = jit_step(state, action)\n",
    "    \n",
    "    \n",
    "    rollout.append(state.pipeline_state)\n",
    "    all_obs.append(state.obs)\n",
    "    all_infos.append(state.info)\n",
    "\n",
    "media.show_video(env.render(rollout, camera=\"track\"), fps=1.0 / env.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf7dfc5",
   "metadata": {},
   "source": [
    "Above, after you've implimented the \"kick\" mechanic to the env, you should see the robot occasionally being pushed in random directions!\n",
    "\n",
    "`#TODO(student)` **TASK 7**: Since you also added each kick to the robot's observation, plot the norm of the kick vector against time using the `all_infos` variable. (5 pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4121d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO(student): Plot the kick magnitude vs time\n",
    "kicks = []\n",
    "\n",
    "kicks = np.array(kicks)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(kicks, marker='o')\n",
    "plt.title(\"Array values\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.zeros((200, 200)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c58e4f1",
   "metadata": {},
   "source": [
    "## Modifying the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7d05b",
   "metadata": {},
   "source": [
    "`#TODO(student)` **TASK 8**: Time to get creative! Change the agent model (`unitree_go2/go2_mjx.xml`) in some way! It can be changing the mesh colors, skybox, or adding enitrely different links! (5 pts)\n",
    "\n",
    "For an extra challenge, try to add an attribute that is actuated (e.g. a tail, eyes, etc)! \n",
    "\n",
    "**WARNING:** make sure to change the agent back if you make any big changes so the next steps work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc69799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'unitreego2'\n",
    "env = envs.get_environment(env_name)\n",
    "\n",
    "# jit reset/step functions for fast runtime\n",
    "jit_reset = jax.jit(env.reset)\n",
    "jit_step = jax.jit(env.step)\n",
    "\n",
    "state = jit_reset(jax.random.PRNGKey(0))\n",
    "\n",
    "plt.imshow(env.render([state.pipeline_state], camera='track')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecaa28b",
   "metadata": {},
   "source": [
    "## Make the Robot Sit on Its Hind Legs\n",
    "\n",
    "The goal of this section is to get the robot to sit on its hind legs. \n",
    "\n",
    "`TODO(student)` **TASK 9**: Use what you've you learned in this notebook to make this custom controller. (5 pts)\n",
    "\n",
    "As a starting point, I've already defined a `sit` keyframe in the [`unitree_go2/go2_mjx.xml`](./unitree_go2/go2_mjx.xml) file. Can you figure out how to use it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_env import UnitreeGo2Env\n",
    "\n",
    "# TODO(student): Make a video of a robot sitting on its hind legs!\n",
    "# Make sure the kick_vel is set to 0 so the robot doesn't fall over\n",
    "sit_env = envs.get_environment(\"unitreego2\", kick_vel=0)\n",
    "\n",
    "# jit reset/step functions for fast runtime\n",
    "jit_reset = jax.jit(sit_env.reset)\n",
    "jit_step = jax.jit(sit_env.step)\n",
    "state = jit_reset(jax.random.PRNGKey(0))\n",
    "\n",
    "rollout = [state.pipeline_state]\n",
    "all_obs = [state.obs]\n",
    "all_infos = [state.info]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(500):\n",
    "    action = jp.zeros(sit_env.sys.nu) \n",
    "    \n",
    "    # Take a step in the environment\n",
    "    state = jit_step(state, action)\n",
    "\n",
    "    rollout.append(state.pipeline_state)\n",
    "\n",
    "media.show_video(sit_env.render(rollout, camera=\"track2\"), fps=1.0 / sit_env.dt) # NOTE: Use the track2 camera to get a head-on shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a80c5f",
   "metadata": {},
   "source": [
    "## Drawing General Shapes with the Right Hand\n",
    "\n",
    "In this last section, we'll be going one step beyond specifying joint position setpoints for making motions on the simulated robot. \n",
    "\n",
    "`#TODO(student)` **TASK 10**: You are tasked with using the front right hand to \"draw\" some shape of your chosing in simulation. (10 pts)\n",
    "\n",
    "As a starting point you can use a basic implimentation of numerical [Inverse Kinematics](https://en.wikipedia.org/wiki/Inverse_kinematics) (see [`ik.py`](./ik.py)). \n",
    "\n",
    "The function `solve_ik(foot_world_pos)` takes as input a desired position of the right foot in the world frame. It then tries to solve for the go2's right leg joints that achieve that position. In other words, it's a mapping between world frame coordinates and the robot's joint angles. Note that if the world frame position is not reachable, the `solve_ik()` function will not converge and will be stuck at some local minima. \n",
    "\n",
    "You can use this mapping to create your shape in cartesian coordinates, then map them to joint angles that can be achieved by the simulated robot. Feel free to make your own shape (e.g, heart, butterflys, leminscates, etc)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f78f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ik import IKSolver\n",
    "\n",
    "# NOTE: the render_foot_cursor argument makes the environment render a trace of the front right foot\n",
    "sit_env = envs.get_environment(\"unitreego2\", render_foot_cursor=True, keyframe_name=\"sit\", kick_vel=0)\n",
    "\n",
    "jit_reset = jax.jit(sit_env.reset)\n",
    "jit_step = jax.jit(sit_env.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(student): Impliment everything you need to draw your shape. \n",
    "\n",
    "# Hint: to use the IKSolver, first define an instance of the \n",
    "# class `ik_solver = IKSolver()` then call `ik_solver.solve_ik(sit_env._init_q, numpy_xyz_world_pos)`\n",
    "\n",
    "state = jit_reset(jax.random.PRNGKey(0))\n",
    "rollout = [state.pipeline_state]\n",
    "\n",
    "q_initial = sit_env._init_q\n",
    "\n",
    "# grab a trajectory\n",
    "num_steps = 400\n",
    "for i in range(num_steps):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68528528",
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(sit_env.render(rollout, width=480, height=480, camera=\"track2\"), fps=1.0 / sit_env.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f261c7",
   "metadata": {},
   "source": [
    "## What to Turn In\n",
    "\n",
    "`#TODO(student):` Please zip the following files and turn them into the assignment on gradescope:\n",
    "1. your `02_lab_student.ipynb` file. Please make sure to fill our your name and umich ID in the first cell\n",
    "2. your modified `custom_env.py` file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
